{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c33652e3-5a03-4659-a262-83196a614d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ad9eac2-2482-4b8a-a047-5327cf7af825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flickr8k():\n",
    "    path = pathlib.Path.cwd()\n",
    "    \n",
    "    if len(list(path.rglob('*'))) < 16197:\n",
    "        tf.keras.utils.get_file(\n",
    "            origin='https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip',\n",
    "            cache_dir=path,\n",
    "            cache_subdir='datasets',\n",
    "            extract=True)\n",
    "        tf.keras.utils.get_file(\n",
    "            origin='https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip',\n",
    "            cache_dir=path,\n",
    "            cache_subdir='datasets',\n",
    "            extract=True)\n",
    "\n",
    "    path = pathlib.Path(str(path) + '\\\\datasets')\n",
    "    \n",
    "    captions = (path/\"Flickr8k.token.txt\").read_text().splitlines()\n",
    "    captions = (line.split('\\t') for line in captions)\n",
    "    captions = ((fname.split('#')[0], caption) for (fname, caption) in captions)\n",
    "    \n",
    "    cap_dict = collections.defaultdict(list)\n",
    "    for fname, cap in captions:\n",
    "        cap_dict[fname].append(cap)\n",
    "    \n",
    "    train_files = (path/'Flickr_8k.trainImages.txt').read_text().splitlines()\n",
    "    train_captions = [(str(path/'Flicker8k_Dataset'/fname), cap_dict[fname]) for fname in train_files]\n",
    "    \n",
    "    test_files = (path/'Flickr_8k.testImages.txt').read_text().splitlines()\n",
    "    test_captions = [(str(path/'Flicker8k_Dataset'/fname), cap_dict[fname]) for fname in test_files]\n",
    "    \n",
    "    train_ds = tf.data.experimental.from_list(train_captions)\n",
    "    test_ds = tf.data.experimental.from_list(test_captions)\n",
    "    \n",
    "    return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02140ec0-653a-44c0-9eaa-012628c91b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw, test_raw = flickr8k()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abd09b85-adc3-4809-892e-af03c085ca73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'D:\\\\Projects\\\\Image_Caption\\\\Image-Caption\\\\Model\\\\datasets\\\\Flicker8k_Dataset\\\\2513260012_03d33305cf.jpg', shape=(), dtype=string)\n",
      "tf.Tensor(\n",
      "[b'A black dog is running after a white dog in the snow .'\n",
      " b'Black dog chasing brown dog through snow'\n",
      " b'Two dogs chase each other across the snowy ground .'\n",
      " b'Two dogs play together in the snow .'\n",
      " b'Two dogs running through a low lying body of water .'], shape=(5,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for ex_path, ex_captions in train_raw.take(1):\n",
    "    print(ex_path)\n",
    "    print(ex_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "547b90f2-b4a5-47a3-be23-32a003a0077c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_large_224_1.0_float_no_top_v2.h5\n",
      "12683000/12683000 [==============================] - 8s 1us/step\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SHAPE=(224, 224, 3)\n",
    "mobilenet = tf.keras.applications.MobileNetV3Large(\n",
    "    input_shape=IMAGE_SHAPE,\n",
    "    include_top=False,\n",
    "    include_preprocessing=True)\n",
    "mobilenet.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "990abe13-62d9-4775-842b-cbf62f31b122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/Projects/Image_Caption/Image-Caption/Model/Model_Data/mobilenet_v3_large_weights.h5')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(pathlib.Path.cwd() / 'Model_Data'):\n",
    "    os.mkdir(pathlib.Path.cwd() / 'Model_Data')\n",
    "shutil.move(pathlib.Path.home() / '.keras/models/weights_mobilenet_v3_large_224_1.0_float_no_top_v2.h5', pathlib.Path.cwd() / 'Model_Data/mobilenet_v3_large_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ee5e2a9-2f32-4034-9692-f02e7515218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, IMAGE_SHAPE[:-1])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea43d1e4-914a-4062-b50b-bab43b8ea739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n",
      "(1, 7, 7, 960)\n"
     ]
    }
   ],
   "source": [
    "test_img_batch = load_image(ex_path)[tf.newaxis, :]\n",
    "\n",
    "print(test_img_batch.shape)\n",
    "print(mobilenet(test_img_batch).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08c7ff2a-35e5-41e4-bb40-0737f9c1ff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(s):\n",
    "    s = tf.strings.lower(s)\n",
    "    s = tf.strings.regex_replace(s, f'[{re.escape(string.punctuation)}]', '')\n",
    "    s = tf.strings.join(['[START]', s, '[END]'], separator=' ')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf9fc936-60b8-4378-bba0-7b0bb55ffa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 5000\n",
    "tokenizer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=vocabulary_size,\n",
    "    standardize=standardize,\n",
    "    ragged=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bee9b92e-8973-44a7-8e0d-f0ca43e2b563",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.adapt(train_raw.map(lambda fp,txt: txt).unbatch().batch(1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f64676-935a-4209-8197-c3346dbb28fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
