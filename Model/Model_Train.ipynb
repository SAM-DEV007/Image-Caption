{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78d204fe-427c-40ef-9554-d2ac02876801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "#tf.config.run_functions_eagerly(True)\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad13b091-8689-47d0-8c8f-a1931c45b681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(save_path, batch_size=32, shuffle=1000, cycle_length=2):\n",
    "    def custom_reader_func(datasets):\n",
    "        datasets = datasets.shuffle(1000)\n",
    "        return datasets.interleave(lambda x: x, cycle_length=cycle_length)\n",
    "\n",
    "    ds = tf.data.Dataset.load(save_path, reader_func=custom_reader_func)\n",
    "    \n",
    "    def drop_index(i, x):\n",
    "        return x\n",
    "    \n",
    "    ds = (ds\n",
    "        .map(drop_index, tf.data.AUTOTUNE)\n",
    "        .shuffle(shuffle)\n",
    "        .padded_batch(batch_size)\n",
    "        .prefetch(tf.data.AUTOTUNE))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2b5d20a-5890-471e-96e6-3a0af4c398d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = load_dataset(str(pathlib.Path.cwd() / 'Model_Data/train_cache'))\n",
    "test_ds = load_dataset(str(pathlib.Path.cwd() / 'Model_Data/test_cache'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb7b338-acde-40c5-8a1a-8d8f3b7b4b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, max_length, depth):\n",
    "        super().__init__()\n",
    "        self.pos_embedding = tf.keras.layers.Embedding(input_dim=max_length, output_dim=depth)\n",
    "        \n",
    "        self.token_embedding = tf.keras.layers.Embedding(\n",
    "            input_dim=vocab_size,\n",
    "            output_dim=depth,\n",
    "            mask_zero=True)\n",
    "        \n",
    "        self.add = tf.keras.layers.Add()\n",
    "    \n",
    "    def call(self, seq):\n",
    "        seq = self.token_embedding(seq) # (batch, seq, depth)\n",
    "        \n",
    "        x = tf.range(tf.shape(seq)[1])  # (seq)\n",
    "        x = x[tf.newaxis, :]  # (1, seq)\n",
    "        x = self.pos_embedding(x)  # (1, seq, depth)\n",
    "        \n",
    "        return self.add([seq, x])\n",
    "\n",
    "\n",
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "\n",
    "class CausalSelfAttention(BaseAttention):\n",
    "    def call(self, x):\n",
    "        attn = self.mha(query=x, value=x,\n",
    "                        use_causal_mask=True)\n",
    "        x = self.add([x, attn])\n",
    "        return self.layernorm(x)\n",
    "\n",
    "\n",
    "class CrossAttention(BaseAttention):\n",
    "    def call(self, x, y, **kwargs):\n",
    "        attn, attention_scores = self.mha(\n",
    "                 query=x, value=y,\n",
    "                 return_attention_scores=True)\n",
    "        \n",
    "        self.last_attention_scores = attention_scores\n",
    "        \n",
    "        x = self.add([x, attn])\n",
    "        return self.layernorm(x)\n",
    "\n",
    "\n",
    "class FeedForward(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.seq = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(units=2*units, activation='relu'),\n",
    "            tf.keras.layers.Dense(units=units),\n",
    "            tf.keras.layers.Dropout(rate=dropout_rate),\n",
    "        ])\n",
    "        self.add = tf.keras.layers.Add()\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.add([x, self.seq(x)])\n",
    "        return self.layernorm(x)\n",
    "\n",
    "\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, num_heads=1, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.self_attention = CausalSelfAttention(num_heads=num_heads,\n",
    "                                                  key_dim=units,\n",
    "                                                  dropout=dropout_rate)\n",
    "        self.cross_attention = CrossAttention(num_heads=num_heads,\n",
    "                                              key_dim=units,\n",
    "                                              dropout=dropout_rate)\n",
    "        self.ff = FeedForward(units=units, dropout_rate=dropout_rate)\n",
    "    \n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        in_seq, out_seq = inputs\n",
    "        \n",
    "        # Text input\n",
    "        out_seq = self.self_attention(out_seq)\n",
    "        out_seq = self.cross_attention(out_seq, in_seq)\n",
    "        self.last_attention_scores = self.cross_attention.last_attention_scores\n",
    "        out_seq = self.ff(out_seq)\n",
    "        return out_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e75ab89-f452-4d82-924d-e27cd78a9968",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenOutput(tf.keras.layers.Layer):\n",
    "    def __init__(self, tokenizer, banned_tokens=('', '[UNK]', '[START]'), **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(\n",
    "            units=tokenizer.vocabulary_size(), **kwargs)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.banned_tokens = banned_tokens\n",
    "        self.bias = None\n",
    "    \n",
    "    def adapt(self, ds):\n",
    "        counts = collections.Counter()\n",
    "        vocab_dict = {name: id \n",
    "                      for id, name in enumerate(self.tokenizer.get_vocabulary())}\n",
    "    \n",
    "        for tokens in tqdm.tqdm(ds):\n",
    "            counts.update(tokens.numpy().flatten())\n",
    "        \n",
    "        counts_arr = np.zeros(shape=(self.tokenizer.vocabulary_size(),))\n",
    "        counts_arr[np.array(list(counts.keys()), dtype=np.int32)] = list(counts.values())\n",
    "        \n",
    "        counts_arr = counts_arr[:]\n",
    "        for token in self.banned_tokens:\n",
    "            counts_arr[vocab_dict[token]] = 0\n",
    "        \n",
    "        total = counts_arr.sum()\n",
    "        p = counts_arr/total\n",
    "        p[counts_arr==0] = 1.0\n",
    "        log_p = np.log(p)  # log(1) == 0\n",
    "        \n",
    "        entropy = -(log_p*p).sum()\n",
    "        \n",
    "        print()\n",
    "        print(f\"Uniform entropy: {np.log(self.tokenizer.vocabulary_size()):0.2f}\")\n",
    "        print(f\"Marginal entropy: {entropy:0.2f}\")\n",
    "        \n",
    "        self.bias = log_p\n",
    "        self.bias[counts_arr==0] = -1e9\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.dense(x)\n",
    "        return x + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef4bee6c-97cf-47f4-b145-4e603352b846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def standardize(s):\n",
    "    s = tf.strings.lower(s)\n",
    "    s = tf.strings.regex_replace(s, f'[{re.escape(string.punctuation)}]', '')\n",
    "    s = tf.strings.join(['[START]', s, '[END]'], separator=' ')\n",
    "    return s\n",
    "\n",
    "\n",
    "from_disk = pickle.load(open(str(pathlib.Path.cwd() / 'Model_Data/tokenizer.pkl'), \"rb\"))\n",
    "tokenizer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=from_disk['config']['max_tokens'],\n",
    "    standardize=standardize,\n",
    "    ragged=True)\n",
    "tokenizer.set_weights(from_disk['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b95fb248-badb-47d1-9625-0e1209bd8bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 938/938 [00:32<00:00, 29.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Uniform entropy: 8.52\n",
      "Marginal entropy: 5.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_layer = TokenOutput(tokenizer, banned_tokens=('', '[UNK]', '[START]'))\n",
    "output_layer.adapt(train_ds.map(lambda inputs, labels: labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b234a909-95a9-42b5-87e8-277a7e511c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Captioner(tf.keras.Model):\n",
    "    @classmethod\n",
    "    def add_method(cls, fun):\n",
    "        setattr(cls, fun.__name__, fun)\n",
    "        return fun\n",
    "    \n",
    "    def __init__(self, tokenizer, feature_extractor, output_layer, num_layers=1,\n",
    "               units=256, max_length=50, num_heads=1, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.tokenizer = tokenizer\n",
    "        self.word_to_index = tf.keras.layers.StringLookup(\n",
    "            mask_token=\"\",\n",
    "            vocabulary=tokenizer.get_vocabulary())\n",
    "        self.index_to_word = tf.keras.layers.StringLookup(\n",
    "            mask_token=\"\",\n",
    "            vocabulary=tokenizer.get_vocabulary(),\n",
    "            invert=True) \n",
    "        \n",
    "        self.seq_embedding = SeqEmbedding(\n",
    "            vocab_size=tokenizer.vocabulary_size(),\n",
    "            depth=units,\n",
    "            max_length=max_length)\n",
    "        \n",
    "        self.decoder_layers = [\n",
    "            DecoderLayer(units, num_heads=num_heads, dropout_rate=dropout_rate)\n",
    "            for n in range(num_layers)]\n",
    "        \n",
    "        self.output_layer = output_layer\n",
    "\n",
    "@Captioner.add_method\n",
    "def call(self, inputs):\n",
    "    image, txt = inputs\n",
    "\n",
    "    if image.shape[-1] == 3:\n",
    "      # Apply the feature-extractor, if you get an RGB image.\n",
    "        image = self.feature_extractor(image)\n",
    "    \n",
    "    # Flatten the feature map\n",
    "    image = einops.rearrange(image, 'b h w c -> b (h w) c')\n",
    "    \n",
    "    \n",
    "    if txt.dtype == tf.string:\n",
    "      # Apply the tokenizer if you get string inputs.\n",
    "        txt = tokenizer(txt)\n",
    "    \n",
    "    txt = self.seq_embedding(txt)\n",
    "    \n",
    "    # Look at the image\n",
    "    for dec_layer in self.decoder_layers:\n",
    "        txt = dec_layer(inputs=(image, txt))\n",
    "    \n",
    "    txt = self.output_layer(txt)\n",
    "    \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28ea3dc9-59ed-4dd1-866b-7b9e140c31ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_large_224_1.0_float_no_top_v2.h5\n",
      "12683000/12683000 [==============================] - 9s 1us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/Projects/Image_Caption/Image-Caption/Model/Model_Data/mobilenet_v3_large_weights.h5')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_SHAPE=(224, 224, 3)\n",
    "mobilenet = tf.keras.applications.MobileNetV3Large(\n",
    "    input_shape=IMAGE_SHAPE,\n",
    "    include_top=False,\n",
    "    include_preprocessing=True)\n",
    "mobilenet.trainable=False\n",
    "\n",
    "if not os.path.exists(pathlib.Path.cwd() / 'Model_Data'):\n",
    "    os.mkdir(pathlib.Path.cwd() / 'Model_Data')\n",
    "shutil.move(pathlib.Path.home() / '.keras/models/weights_mobilenet_v3_large_224_1.0_float_no_top_v2.h5', pathlib.Path.cwd() / 'Model_Data/mobilenet_v3_large_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f5c03c2-8c40-429e-8860-909934d4cc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Captioner(tokenizer, feature_extractor=mobilenet, output_layer=output_layer,\n",
    "                  units=256, dropout_rate=0.5, num_layers=2, num_heads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09a0f23f-6833-43ef-b9c0-44eb7ee6fbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Captioner.add_method\n",
    "def simple_gen(self, image, temperature=1):\n",
    "    initial = self.word_to_index([['[START]']]) # (batch, sequence)\n",
    "    img_features = self.feature_extractor(image[tf.newaxis, ...])\n",
    "    \n",
    "    tokens = initial # (batch, sequence)\n",
    "    for n in range(50):\n",
    "        preds = self((img_features, tokens)).numpy()  # (batch, sequence, vocab)\n",
    "        preds = preds[:,-1, :]  #(batch, vocab)\n",
    "        if temperature==0:\n",
    "            next = tf.argmax(preds, axis=-1)[:, tf.newaxis]  # (batch, 1)\n",
    "        else:\n",
    "            next = tf.random.categorical(preds/temperature, num_samples=1)  # (batch, 1)\n",
    "        tokens = tf.concat([tokens, next], axis=1) # (batch, sequence) \n",
    "        \n",
    "        if next[0] == self.word_to_index('[END]'):\n",
    "            break\n",
    "    words = self.index_to_word(tokens[0, 1:-1])\n",
    "    result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
    "    return result.numpy().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a1bedaf-5a96-4de8-bd1e-f55ca448e0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(labels, preds):  \n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels, preds)\n",
    "    \n",
    "    mask = (labels != 0) & (loss < 1e8) \n",
    "    mask = tf.cast(mask, loss.dtype)\n",
    "    \n",
    "    loss = loss*mask\n",
    "    loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "    return loss\n",
    "\n",
    "def masked_acc(labels, preds):\n",
    "    mask = tf.cast(labels!=0, tf.float32)\n",
    "    preds = tf.argmax(preds, axis=-1)\n",
    "    labels = tf.cast(labels, tf.int64)\n",
    "    match = tf.cast(preds == labels, mask.dtype)\n",
    "    acc = tf.reduce_sum(match*mask)/tf.reduce_sum(mask)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cce9e32-bb7c-4580-b297-f79d1f3fae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, IMAGE_SHAPE[:-1])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "056cbd07-4eab-4599-8464-83d4f4a17eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateText(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        path = pathlib.Path.cwd() / 'Model_Data'\n",
    "        image_url = 'https://tensorflow.org/images/surf.jpg'\n",
    "        image_path = tf.keras.utils.get_file('surf.jpg', origin=image_url, cache_dir=path, cache_subdir=(path / 'train_check'))\n",
    "        self.image = load_image(image_path)\n",
    "    \n",
    "    def on_epoch_end(self, epochs=None, logs=None):\n",
    "        print()\n",
    "        print()\n",
    "        for t in (0.0, 0.5, 1.0):\n",
    "            result = self.model.simple_gen(self.image, temperature=t)\n",
    "            print(result)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb50f1dc-81c7-4c75-bdb2-ba5886d7a643",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save = pathlib.Path.cwd() / 'Model_Data/weights/model.tf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4f62225-24a3-41db-9ebc-582f4e185884",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    GenerateText(),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        patience=5, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        model_save, verbose=1, monitor='val_masked_acc', mode='max', save_best_only=True, save_weights_only=True, save_format='tf')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc8277d4-22a3-44b0-ad26-cb2fbdbfa20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "           loss=masked_loss,\n",
    "           metrics=[masked_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81b6a768-8ea8-40b1-9c2f-1cb45315c052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.0063 - masked_acc: 0.1967\n",
      "\n",
      "a man in a man in a man\n",
      "a man of a water\n",
      "a to playing woman across surfboard group girl six area spins camera on the two\n",
      "\n",
      "\n",
      "Epoch 1: val_masked_acc improved from -inf to 0.24455, saving model to D:\\Projects\\Image_Caption\\Image-Caption\\Model\\Model_Data\\weights\\model.tf\n",
      "100/100 [==============================] - 15s 100ms/step - loss: 5.0063 - masked_acc: 0.1967 - val_loss: 4.6118 - val_masked_acc: 0.2445\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.6086 - masked_acc: 0.2562\n",
      "\n",
      "a man in a red is in a water\n",
      "a man in a child in a water\n",
      "the restaurant in red red background\n",
      "\n",
      "\n",
      "Epoch 2: val_masked_acc improved from 0.24455 to 0.26768, saving model to D:\\Projects\\Image_Caption\\Image-Caption\\Model\\Model_Data\\weights\\model.tf\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 4.6086 - masked_acc: 0.2562 - val_loss: 4.3867 - val_masked_acc: 0.2677\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.3522 - masked_acc: 0.2838\n",
      "\n",
      "a man in a red is is in a man in a water\n",
      "a man in the water\n",
      "a jumping in a street at the mask other\n",
      "\n",
      "\n",
      "Epoch 3: val_masked_acc improved from 0.26768 to 0.30185, saving model to D:\\Projects\\Image_Caption\\Image-Caption\\Model\\Model_Data\\weights\\model.tf\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 4.3522 - masked_acc: 0.2838 - val_loss: 4.1289 - val_masked_acc: 0.3019\n",
      "Epoch 4/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 4.2095 - masked_acc: 0.2982\n",
      "\n",
      "a man in a red is in the water\n",
      "a boy is in a water\n",
      "a girl is with a red through an cliff small\n",
      "\n",
      "\n",
      "Epoch 4: val_masked_acc improved from 0.30185 to 0.31105, saving model to D:\\Projects\\Image_Caption\\Image-Caption\\Model\\Model_Data\\weights\\model.tf\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 4.2088 - masked_acc: 0.2984 - val_loss: 4.0130 - val_masked_acc: 0.3110\n",
      "Epoch 5/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 4.0857 - masked_acc: 0.3127\n",
      "\n",
      "a man in a red shirt is in the water\n",
      "a boy is in the water\n",
      "a man jumping flying is running stands in the water\n",
      "\n",
      "\n",
      "Epoch 5: val_masked_acc improved from 0.31105 to 0.33159, saving model to D:\\Projects\\Image_Caption\\Image-Caption\\Model\\Model_Data\\weights\\model.tf\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 4.0806 - masked_acc: 0.3133 - val_loss: 3.8475 - val_masked_acc: 0.3316\n",
      "Epoch 6/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 3.9981 - masked_acc: 0.3226\n",
      "\n",
      "a man is jumping through the water\n",
      "a person in a green red and a red beach\n",
      "a wading stands through the water\n",
      "\n",
      "\n",
      "Epoch 6: val_masked_acc improved from 0.33159 to 0.33611, saving model to D:\\Projects\\Image_Caption\\Image-Caption\\Model\\Model_Data\\weights\\model.tf\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 3.9984 - masked_acc: 0.3230 - val_loss: 3.8192 - val_masked_acc: 0.3361\n",
      "Epoch 7/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 3.8742 - masked_acc: 0.3329\n",
      "\n",
      "a man in a red shirt is in the water\n",
      "a man playing through the water\n",
      "a group of people riding a camera at a rural behind a red guitar\n",
      "\n",
      "\n",
      "Epoch 7: val_masked_acc improved from 0.33611 to 0.33888, saving model to D:\\Projects\\Image_Caption\\Image-Caption\\Model\\Model_Data\\weights\\model.tf\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 3.8767 - masked_acc: 0.3327 - val_loss: 3.7182 - val_masked_acc: 0.3389\n",
      "Epoch 8/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 3.8205 - masked_acc: 0.3381\n",
      "\n",
      "a man in a red shirt is running through the water\n",
      "a man in a woman is standing in the water\n",
      "the brown snowboarder wearing the night\n",
      "\n",
      "\n",
      "Epoch 8: val_masked_acc did not improve from 0.33888\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 3.8199 - masked_acc: 0.3384 - val_loss: 3.6985 - val_masked_acc: 0.3383\n",
      "Epoch 9/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 3.7505 - masked_acc: 0.3417\n",
      "\n",
      "a man is jumping in a wave\n",
      "a man in a red shirt is is holding a wave\n",
      "a man wearing a blue and a hand into ground with snow\n",
      "\n",
      "\n",
      "Epoch 9: val_masked_acc improved from 0.33888 to 0.35033, saving model to D:\\Projects\\Image_Caption\\Image-Caption\\Model\\Model_Data\\weights\\model.tf\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 3.7517 - masked_acc: 0.3415 - val_loss: 3.5975 - val_masked_acc: 0.3503\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.6686 - masked_acc: 0.3470\n",
      "\n",
      "a man in a red shirt is in the water\n",
      "a man in a blue jacket is running in a wave\n",
      "a man is in a sandy blue top hanging\n",
      "\n",
      "\n",
      "Epoch 10: val_masked_acc improved from 0.35033 to 0.35490, saving model to D:\\Projects\\Image_Caption\\Image-Caption\\Model\\Model_Data\\weights\\model.tf\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 3.6686 - masked_acc: 0.3470 - val_loss: 3.5184 - val_masked_acc: 0.3549\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.5515 - masked_acc: 0.3596\n",
      "\n",
      "a man is in a wave\n",
      "a man in a red is in a surfboard\n",
      "a man standing\n",
      "\n",
      "\n",
      "Epoch 11: val_masked_acc improved from 0.35490 to 0.36376, saving model to D:\\Projects\\Image_Caption\\Image-Caption\\Model\\Model_Data\\weights\\model.tf\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 3.5515 - masked_acc: 0.3596 - val_loss: 3.4800 - val_masked_acc: 0.3638\n",
      "Epoch 12/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 3.5511 - masked_acc: 0.3581\n",
      "\n",
      "a man in a yellow shirt is jumping into the water\n",
      "a man in a yellow jacket is in a wave\n",
      "a guy climbing on a swimming performs climb into a wave\n",
      "\n",
      "\n",
      "Epoch 12: val_masked_acc improved from 0.36376 to 0.36739, saving model to D:\\Projects\\Image_Caption\\Image-Caption\\Model\\Model_Data\\weights\\model.tf\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 3.5511 - masked_acc: 0.3581 - val_loss: 3.4238 - val_masked_acc: 0.3674\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.5085 - masked_acc: 0.3632\n",
      "\n",
      "a man in a red shirt is jumping over a wave\n",
      "a child in a red jacket is walking in a wave\n",
      "two hands on a lone play in the ocean\n",
      "\n",
      "\n",
      "Epoch 13: val_masked_acc did not improve from 0.36739\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 3.5085 - masked_acc: 0.3632 - val_loss: 3.4278 - val_masked_acc: 0.3541\n",
      "Epoch 14/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 3.4710 - masked_acc: 0.3657\n",
      "\n",
      "a man in a red shirt is jumping into the water\n",
      "a man is a blue jacket is riding a surfboard\n",
      "a woman in the clothing sits swing\n",
      "\n",
      "\n",
      "Epoch 14: val_masked_acc did not improve from 0.36739\n",
      "100/100 [==============================] - 7s 73ms/step - loss: 3.4714 - masked_acc: 0.3654 - val_loss: 3.4144 - val_masked_acc: 0.3590\n",
      "Epoch 15/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 3.4398 - masked_acc: 0.3687\n",
      "\n",
      "a man in a yellow shirt is in the water\n",
      "a man is in the water\n",
      "a man is jumping in the wave\n",
      "\n",
      "\n",
      "Epoch 15: val_masked_acc improved from 0.36739 to 0.37273, saving model to D:\\Projects\\Image_Caption\\Image-Caption\\Model\\Model_Data\\weights\\model.tf\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 3.4420 - masked_acc: 0.3680 - val_loss: 3.2971 - val_masked_acc: 0.3727\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3917 - masked_acc: 0.3695\n",
      "\n",
      "a man in a blue shirt is riding a wave\n",
      "a man in a yellow shirt is jumping over the water\n",
      "the woman man is jumping on a ink is off\n",
      "\n",
      "\n",
      "Epoch 16: val_masked_acc did not improve from 0.37273\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 3.3917 - masked_acc: 0.3695 - val_loss: 3.3408 - val_masked_acc: 0.3645\n",
      "Epoch 17/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 3.3437 - masked_acc: 0.3746\n",
      "\n",
      "a man in a red shirt is jumping over a wave\n",
      "a person is in a wave\n",
      "two men racing in the sunset on a ball\n",
      "\n",
      "\n",
      "Epoch 17: val_masked_acc did not improve from 0.37273\n",
      "100/100 [==============================] - 7s 72ms/step - loss: 3.3434 - masked_acc: 0.3749 - val_loss: 3.2627 - val_masked_acc: 0.3714\n",
      "Epoch 18/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 3.3876 - masked_acc: 0.3695\n",
      "\n",
      "a man in a red shirt is riding a wave\n",
      "a person is jumping in the ocean\n",
      "a person watching a raft off the wave another person in a red attempt over his body splashing through background\n",
      "\n",
      "\n",
      "Epoch 18: val_masked_acc improved from 0.37273 to 0.37952, saving model to D:\\Projects\\Image_Caption\\Image-Caption\\Model\\Model_Data\\weights\\model.tf\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 3.3869 - masked_acc: 0.3696 - val_loss: 3.2108 - val_masked_acc: 0.3795\n",
      "Epoch 19/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 3.3172 - masked_acc: 0.3778\n",
      "\n",
      "a man in a red shirt is riding a wave\n",
      "a person is on a wave\n",
      "a surfer is getting her beach in the ocean\n",
      "\n",
      "\n",
      "Epoch 19: val_masked_acc did not improve from 0.37952\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 3.3169 - masked_acc: 0.3777 - val_loss: 3.2870 - val_masked_acc: 0.3706\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2048 - masked_acc: 0.3891\n",
      "\n",
      "a man is riding a wave\n",
      "a surfer is riding a wave\n",
      "a man climb the shore off a orange motorcycle\n",
      "\n",
      "\n",
      "Epoch 20: val_masked_acc improved from 0.37952 to 0.38089, saving model to D:\\Projects\\Image_Caption\\Image-Caption\\Model\\Model_Data\\weights\\model.tf\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 3.2048 - masked_acc: 0.3891 - val_loss: 3.1879 - val_masked_acc: 0.3809\n",
      "Epoch 21/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 3.1764 - masked_acc: 0.3890\n",
      "\n",
      "a man is riding a wave\n",
      "a boy in a white wetsuit is wearing a blue surfboard\n",
      "a is kissing a wave on his water\n",
      "\n",
      "\n",
      "Epoch 21: val_masked_acc did not improve from 0.38089\n",
      "100/100 [==============================] - 7s 73ms/step - loss: 3.1777 - masked_acc: 0.3889 - val_loss: 3.1989 - val_masked_acc: 0.3773\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.1902 - masked_acc: 0.3875\n",
      "\n",
      "a man in a red wetsuit is riding a wave\n",
      "a man in a black wetsuit is riding a wave\n",
      "a woman on waves are along the tricks\n",
      "\n",
      "\n",
      "Epoch 22: val_masked_acc improved from 0.38089 to 0.38601, saving model to D:\\Projects\\Image_Caption\\Image-Caption\\Model\\Model_Data\\weights\\model.tf\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 3.1902 - masked_acc: 0.3875 - val_loss: 3.1534 - val_masked_acc: 0.3860\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.1799 - masked_acc: 0.3894\n",
      "\n",
      "a man in a red wetsuit is riding a wave\n",
      "a person is surfing a wave\n",
      "the man in a red is wave on the ocean\n",
      "\n",
      "\n",
      "Epoch 23: val_masked_acc did not improve from 0.38601\n",
      "100/100 [==============================] - 7s 74ms/step - loss: 3.1799 - masked_acc: 0.3894 - val_loss: 3.1593 - val_masked_acc: 0.3803\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.1555 - masked_acc: 0.3868\n",
      "\n",
      "a man in a red shirt is riding a wave\n",
      "a man in a red surfboard is riding a wave\n",
      "the surfer in a swim wave on the wave\n",
      "\n",
      "\n",
      "Epoch 24: val_masked_acc did not improve from 0.38601\n",
      "100/100 [==============================] - 7s 74ms/step - loss: 3.1555 - masked_acc: 0.3868 - val_loss: 3.2044 - val_masked_acc: 0.3751\n",
      "Epoch 25/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 3.1405 - masked_acc: 0.3899\n",
      "\n",
      "a man in a red shirt is riding a wave\n",
      "a man in a red shirt is riding a wave\n",
      "a man in swim slide\n",
      "\n",
      "\n",
      "Epoch 25: val_masked_acc did not improve from 0.38601\n",
      "100/100 [==============================] - 7s 73ms/step - loss: 3.1386 - masked_acc: 0.3903 - val_loss: 3.1424 - val_masked_acc: 0.3828\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0712 - masked_acc: 0.3953\n",
      "\n",
      "a man is riding a wave\n",
      "a person in a red shirt riding a wave\n",
      "his mountains in a lake\n",
      "\n",
      "\n",
      "Epoch 26: val_masked_acc did not improve from 0.38601\n",
      "100/100 [==============================] - 7s 69ms/step - loss: 3.0712 - masked_acc: 0.3953 - val_loss: 3.1163 - val_masked_acc: 0.3808\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0612 - masked_acc: 0.3976\n",
      "\n",
      "a man in a red shirt is riding a wave\n",
      "a man in a yellow wetsuit is riding a wave\n",
      "a man on the crane is riding a tank while doing the fishing surfboard watches\n",
      "\n",
      "\n",
      "Epoch 27: val_masked_acc did not improve from 0.38601\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 3.0612 - masked_acc: 0.3976 - val_loss: 3.0472 - val_masked_acc: 0.3850\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0529 - masked_acc: 0.3986\n",
      "\n",
      "a man is riding a wave on a wave\n",
      "a man is riding a wave on a surfboard\n",
      "a wetsuit with many sea sleeveless through the wave towards the him\n",
      "\n",
      "\n",
      "Epoch 28: val_masked_acc improved from 0.38601 to 0.38903, saving model to D:\\Projects\\Image_Caption\\Image-Caption\\Model\\Model_Data\\weights\\model.tf\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 3.0529 - masked_acc: 0.3986 - val_loss: 3.0370 - val_masked_acc: 0.3890\n",
      "Epoch 29/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2.9535 - masked_acc: 0.4089\n",
      "\n",
      "a surfer in a yellow surfboard is riding a wave\n",
      "a surfer in a yellow shirt is surfing\n",
      "a small surfer in a yellow rides foliage in the ocean\n",
      "\n",
      "\n",
      "Epoch 29: val_masked_acc improved from 0.38903 to 0.39704, saving model to D:\\Projects\\Image_Caption\\Image-Caption\\Model\\Model_Data\\weights\\model.tf\n",
      "100/100 [==============================] - 9s 90ms/step - loss: 2.9545 - masked_acc: 0.4091 - val_loss: 2.9941 - val_masked_acc: 0.3970\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9732 - masked_acc: 0.4107\n",
      "\n",
      "a man in a yellow shirt is surfing\n",
      "a man in a yellow shirt is riding a surfboard\n",
      "the surfer in a white with an in the large stream\n",
      "\n",
      "\n",
      "Epoch 30: val_masked_acc improved from 0.39704 to 0.39882, saving model to D:\\Projects\\Image_Caption\\Image-Caption\\Model\\Model_Data\\weights\\model.tf\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 2.9732 - masked_acc: 0.4107 - val_loss: 3.0060 - val_masked_acc: 0.3988\n",
      "Epoch 31/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2.9800 - masked_acc: 0.4059\n",
      "\n",
      "a surfer is riding a wave\n",
      "a person is splashing through a wave\n",
      "someone riding a through the ocean\n",
      "\n",
      "\n",
      "Epoch 31: val_masked_acc did not improve from 0.39882\n",
      "100/100 [==============================] - 7s 67ms/step - loss: 2.9813 - masked_acc: 0.4062 - val_loss: 3.0611 - val_masked_acc: 0.3863\n",
      "Epoch 32/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2.9552 - masked_acc: 0.4052\n",
      "\n",
      "a man in a red wetsuit is riding a wave\n",
      "a surfer on a wave\n",
      "a man splashes in the waves\n",
      "\n",
      "\n",
      "Epoch 32: val_masked_acc did not improve from 0.39882\n",
      "100/100 [==============================] - 7s 67ms/step - loss: 2.9568 - masked_acc: 0.4052 - val_loss: 2.9856 - val_masked_acc: 0.3966\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8894 - masked_acc: 0.4099\n",
      "\n",
      "a man in a red shirt is riding a wave\n",
      "a man is riding a wave on a wave\n",
      "person flying along a young man in the ocean in a brown is surfing\n",
      "\n",
      "\n",
      "Epoch 33: val_masked_acc did not improve from 0.39882\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 2.8894 - masked_acc: 0.4099 - val_loss: 3.0173 - val_masked_acc: 0.3919\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9393 - masked_acc: 0.4081\n",
      "\n",
      "a man in a red shirt is riding a wave\n",
      "a surfer rides a wave\n",
      "a surfer in a red helmet rides a wave\n",
      "\n",
      "\n",
      "Epoch 34: val_masked_acc did not improve from 0.39882\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 2.9393 - masked_acc: 0.4081 - val_loss: 2.9785 - val_masked_acc: 0.3903\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8912 - masked_acc: 0.4118\n",
      "\n",
      "a man in a red shirt is riding a wave\n",
      "a surfer is riding a surfboard on a wave\n",
      "man throws a yellow board to countryside\n",
      "\n",
      "\n",
      "Epoch 35: val_masked_acc did not improve from 0.39882\n",
      "100/100 [==============================] - 7s 69ms/step - loss: 2.8912 - masked_acc: 0.4118 - val_loss: 3.0158 - val_masked_acc: 0.3868\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8845 - masked_acc: 0.4129\n",
      "\n",
      "a man in a red shirt is surfing\n",
      "two men are in the ocean\n",
      "a man tries to each other on man surfer on one rock\n",
      "\n",
      "\n",
      "Epoch 36: val_masked_acc did not improve from 0.39882\n",
      "100/100 [==============================] - 7s 67ms/step - loss: 2.8845 - masked_acc: 0.4129 - val_loss: 3.0310 - val_masked_acc: 0.3894\n",
      "Epoch 37/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2.8642 - masked_acc: 0.4167\n",
      "\n",
      "a surfer is riding a wave\n",
      "a surfer rides a wave\n",
      "a man wave on a house floating on the waves\n",
      "\n",
      "\n",
      "Epoch 37: val_masked_acc did not improve from 0.39882\n",
      "100/100 [==============================] - 7s 67ms/step - loss: 2.8662 - masked_acc: 0.4166 - val_loss: 3.0052 - val_masked_acc: 0.3929\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8067 - masked_acc: 0.4225\n",
      "\n",
      "a surfer is riding a wave\n",
      "a man in a red helmet is riding a wave\n",
      "a person with a girl slides out to kayak that is pulling a beach near a raft\n",
      "\n",
      "\n",
      "Epoch 38: val_masked_acc did not improve from 0.39882\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 2.8067 - masked_acc: 0.4225 - val_loss: 2.9930 - val_masked_acc: 0.3900\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7669 - masked_acc: 0.4260\n",
      "\n",
      "a man in a red shirt is riding a wave\n",
      "a surfer rides a wave\n",
      "two surfer on the wave in the ocean rides the sky\n",
      "\n",
      "\n",
      "Epoch 39: val_masked_acc did not improve from 0.39882\n",
      "100/100 [==============================] - 7s 71ms/step - loss: 2.7669 - masked_acc: 0.4260 - val_loss: 2.9935 - val_masked_acc: 0.3902\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds.repeat(),\n",
    "    steps_per_epoch=100,\n",
    "    validation_data=test_ds.repeat(),\n",
    "    validation_steps=20,\n",
    "    epochs=100,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "083cfb64-ad21-4fac-9535-db475ec49f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a man in a red shirt is riding a wave'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.simple_gen(load_image(str(pathlib.Path.cwd() / 'Model_Data/train_check/surf.jpg')), temperature=0.0)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
